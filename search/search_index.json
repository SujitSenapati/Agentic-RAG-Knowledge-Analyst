{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Agentic RAG \u2013 Enterprise Knowledge Analyst","text":"<p>This site contains: - High-level architecture documentation - Auto-generated API documentation from Python docstrings (mkdocstrings)</p>"},{"location":"#quick-links","title":"Quick links","text":"<ul> <li>See Architecture</li> <li>See API reference pages</li> </ul>"},{"location":"architecture/","title":"System Architecture","text":"<p>This document describes the end-to-end architecture of the Agentic RAG \u2013 Enterprise Knowledge Analyst system.</p> <p>The system is intentionally split into two distinct phases:</p> <ol> <li>Offline Ingestion Phase \u2013 deterministic data preparation</li> <li>Online Agent Runtime Phase \u2013 dynamic agent reasoning</li> </ol>"},{"location":"architecture/#1-original-agentic-rag-architecture-conceptual-core","title":"1. Original Agentic RAG Architecture (Conceptual Core)","text":"<p>This conceptual architecture remains valid and continues to guide the implementation.</p> <pre><code>flowchart TD\n  U[User] --&gt; UI[Gradio UI]\n  UI --&gt; A[Agent Loop]\n\n  A --&gt; P[Planner]\n  P --&gt;|plan: intent, tools, clarification| A\n\n  A --&gt; TE[Tool Executor]\n  TE --&gt; R1[K8s Docs]\n  TE --&gt; R2[Incidents]\n  TE --&gt; R3[Policy]\n\n  R1 --&gt; EV[Evidence]\n  R2 --&gt; EV\n  R3 --&gt; EV\n\n  EV --&gt; RS[Reasoner]\n  RS --&gt; ANS[Draft Answer]\n\n  ANS --&gt; C[Critic]\n  C --&gt;|Refine if needed| RS\n\n  RS --&gt; J[LLM Judge]\n  J --&gt;|Approve| UI\n  J --&gt;|Retry once| RS\n\n  A -. traces .-&gt; LS[LangSmith]</code></pre>"},{"location":"architecture/#2-final-architecture-full-system-view","title":"2. Final Architecture (Full System View)","text":"<p>The final system extends the original design with:</p> <ul> <li>Offline ingestion</li> <li>Persistent vector stores</li> <li>Capability-based tools</li> <li>Tool registry</li> <li>Multi-layer answer verification</li> <li>Controlled auto-retry</li> </ul> <pre><code>flowchart LR\n\n  %% ------------------------\n  %% Offline Ingestion Phase\n  %% ------------------------\n  subgraph Offline[\"Offline Ingestion Phase\"]\n      U1[Public URLs] --&gt; F[Fetch &amp; Clean HTML]\n      F --&gt; C[Chunking]\n      C --&gt; E[Embedding]\n      E --&gt; VS[(Persistent Vector Stores)]\n  end\n\n  %% ------------------------\n  %% Online Runtime Phase\n  %% ------------------------\n  subgraph Online[\"Online Agent Runtime\"]\n\n      User[User] --&gt; UI[Gradio UI]\n      UI --&gt; A[Agent Loop]\n\n      A --&gt; P[Planner]\n      P --&gt;|Select tools| TR[Tool Registry]\n\n      TR --&gt; T1[Tool: Kubernetes Docs]\n      TR --&gt; T2[Tool: Incident Reports]\n      TR --&gt; T3[Tool: Policy / GDPR]\n      TR --&gt; T4[Tool: StackOverflow]\n      TR --&gt; T5[Tool: OpenAI API Docs]\n      TR --&gt; T6[Tool: GitHub Issues]\n\n      T1 --&gt; VS\n      T2 --&gt; VS\n      T3 --&gt; VS\n      T4 --&gt; VS\n      T5 --&gt; VS\n      T6 --&gt; VS\n\n      VS --&gt; EV[Evidence Builder]\n      EV --&gt; RS[Reasoner]\n      RS --&gt; ANS[Grounded Answer + Citations]\n\n      ANS --&gt; C[Critic / Verifier]\n      C --&gt;|OK| UI\n      C --&gt;|Retry / Refine| A\n\n      A -. traces .-&gt; LS[LangSmith Tracing]\n  end</code></pre>"},{"location":"api/agent_loop/","title":"Agent Loop","text":""},{"location":"api/agent_loop/#module-overview","title":"Module Overview","text":"<p>Agent execution loop.</p> <p>Orchestrates: - Planning - Clarification - Retrieval - Reasoning - Critique - Judge evaluation - Judge-based auto-retry</p>"},{"location":"api/agent_loop/#app.agent.agent_loop.run_agent","title":"run_agent","text":"<pre><code>run_agent(question: str)\n</code></pre> <p>Run the full agent loop.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>User question</p> required <p>Returns:</p> Type Description <p>Tuple[str, Dict]: Final answer and agent trace</p> Source code in <code>app/agent/agent_loop.py</code> <pre><code>def run_agent(question: str):\n    \"\"\"\n    Run the full agent loop.\n\n    Args:\n        question (str): User question\n\n    Returns:\n        Tuple[str, Dict]: Final answer and agent trace\n    \"\"\"\n\n    # =========================\n    # Initialize trace\n    # =========================\n    trace = {\n        \"question\": question\n    }\n\n    # =========================\n    # Planning\n    # =========================\n    plan = create_plan(question)\n\n    trace[\"plan\"] = {\n        \"intent\": plan.intent,\n        \"subquestions\": plan.subquestions,\n        \"tools\": plan.tools,\n        \"need_clarification\": plan.need_clarification,\n        \"clarification_question\": plan.clarification_question,\n    }\n\n    print(trace[\"plan\"])\n\n    # =========================\n    # Clarification path\n    # =========================\n    if plan.need_clarification:\n        trace[\"final_state\"] = \"clarification\"\n        return plan.clarification_question, trace\n\n    # =========================\n    # Retrieval\n    # =========================\n    evidence = retrieve_and_build_evidence(\n        tools=plan.tools,\n        query=question\n    )\n\n    trace[\"evidence_size\"] = len(evidence)\n\n    # =========================\n    # Reasoning\n    # =========================\n    answer = reason(question, evidence)\n\n    # =========================\n    # Critic (logical sanity check)\n    # =========================\n    critic_feedback = critique_answer(\n        question=question,\n        answer=answer,\n        evidence=evidence\n    )\n\n    trace[\"critic\"] = critic_feedback\n\n    # If critic flags a hard failure, refine once\n    if critic_feedback.get(\"needs_revision\"):\n        trace[\"critic_revision\"] = True\n\n        answer = reason(\n            question,\n            evidence,\n            critique=critic_feedback.get(\"rationale\")\n        )\n\n    # =========================\n    # Judge (quality evaluator)\n    # =========================\n    judge = judge_answer(\n        question=question,\n        answer=answer,\n        evidence=evidence\n    )\n\n    trace[\"judge\"] = judge\n\n    # =========================\n    # Judge-based auto-retry (ONE TIME)\n    # =========================\n    if judge[\"verdict\"] == \"needs_review\":\n        trace[\"auto_retry\"] = True\n\n        retry_prompt = load_prompt(\"reasoner_retry.txt\").format(\n            question=question,\n            answer=answer,\n            judge_rationale=judge[\"rationale\"],\n            evidence=evidence\n        )\n\n        revised_answer = llm_fast.invoke(retry_prompt).content.strip()\n\n        retry_judge = judge_answer(\n            question=question,\n            answer=revised_answer,\n            evidence=evidence\n        )\n\n        trace[\"retry\"] = {\n            \"judge\": retry_judge\n        }\n\n        # Accept retry only if it improves quality\n        if retry_judge[\"score\"] &gt;= judge[\"score\"]:\n            answer = revised_answer\n            trace[\"judge\"] = retry_judge\n\n    # =========================\n    # Finalize\n    # =========================\n    trace[\"final_state\"] = \"answered\"\n    return answer, trace\n</code></pre>"},{"location":"api/critic/","title":"Critic","text":""},{"location":"api/critic/#module-overview","title":"Module Overview","text":"<p>Critic module.</p> <p>Performs a lightweight logical consistency check on the agent's answer before final evaluation by the judge.</p>"},{"location":"api/critic/#app.agent.critic.critique_answer","title":"critique_answer","text":"<pre><code>critique_answer(question: str, answer: str, evidence: str) -&gt; dict\n</code></pre> <p>Critique the agent's answer for logical consistency and alignment.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>Original user question</p> required <code>answer</code> <code>str</code> <p>Agent-generated answer</p> required <code>evidence</code> <code>str</code> <p>Evidence used during reasoning</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Critic feedback with needs_revision flag and rationale</p> Source code in <code>app/agent/critic.py</code> <pre><code>def critique_answer(question: str, answer: str, evidence: str) -&gt; dict:\n    \"\"\"\n    Critique the agent's answer for logical consistency and alignment.\n\n    Args:\n        question (str): Original user question\n        answer (str): Agent-generated answer\n        evidence (str): Evidence used during reasoning\n\n    Returns:\n        dict: Critic feedback with needs_revision flag and rationale\n    \"\"\"\n\n    # Load the critic prompt template\n    template = load_prompt(\"critic.txt\")\n\n    # \ud83d\udd11 Inject question, answer, and evidence into the prompt\n    prompt = template.format(\n        question=question,\n        answer=answer,\n        evidence=evidence\n    )\n\n    # Invoke LLM\n    response = llm_fast.invoke(prompt).content.strip()\n\n    # Parse strict JSON\n    return json.loads(response)\n</code></pre>"},{"location":"api/evidence/","title":"Evidence","text":""},{"location":"api/evidence/#module-overview","title":"Module Overview","text":"<p>Evidence construction utilities.</p> <p>Responsibilities: - Deduplicate retrieved documents - Limit the amount of evidence passed to the LLM - Format evidence with citations for traceability - Provide a consistent, auditable evidence block</p> <p>This module does NOT perform reasoning or retrieval.</p>"},{"location":"api/evidence/#app.tools.evidence.build_evidence","title":"build_evidence","text":"<pre><code>build_evidence(docs, limit: int = 15) -&gt; str\n</code></pre> <p>Build a formatted evidence block from retrieved documents.</p> <p>Each evidence entry includes: - Source name - Chunk ID - Source URL - Truncated content snippet</p> <p>Parameters:</p> Name Type Description Default <code>docs</code> <code>list[Document]</code> <p>Retrieved LangChain documents</p> required <code>limit</code> <code>int</code> <p>Maximum number of evidence entries</p> <code>15</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Formatted evidence text</p> Source code in <code>app/tools/evidence.py</code> <pre><code>def build_evidence(docs, limit: int = 15) -&gt; str:\n    \"\"\"\n    Build a formatted evidence block from retrieved documents.\n\n    Each evidence entry includes:\n    - Source name\n    - Chunk ID\n    - Source URL\n    - Truncated content snippet\n\n    Args:\n        docs (list[Document]): Retrieved LangChain documents\n        limit (int): Maximum number of evidence entries\n\n    Returns:\n        str: Formatted evidence text\n    \"\"\"\n    seen = set()\n    evidence_blocks = []\n\n    for doc in docs:\n        key = (doc.metadata[\"url\"], doc.metadata[\"chunk_id\"])\n\n        if key in seen:\n            continue\n\n        seen.add(key)\n\n        evidence_blocks.append(\n            f\"[{doc.metadata['source_name']}|{doc.metadata['chunk_id']}]\"\n            f\"({doc.metadata['url']})\\n\"\n            f\"{doc.page_content[:400]}\"\n        )\n\n        if len(evidence_blocks) &gt;= limit:\n            break\n\n    return \"\\n\\n\".join(evidence_blocks)\n</code></pre>"},{"location":"api/evidence/#app.tools.evidence.retrieve_and_build_evidence","title":"retrieve_and_build_evidence","text":"<pre><code>retrieve_and_build_evidence(tools: list, query: str, limit: int = 15) -&gt; str\n</code></pre> <p>Retrieve documents using selected tools and build formatted evidence.</p> <p>Parameters:</p> Name Type Description Default <code>tools</code> <code>list</code> <p>List of tool names selected by the planner</p> required <code>query</code> <code>str</code> <p>User question</p> required <code>limit</code> <code>int</code> <p>Maximum number of evidence entries</p> <code>15</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Formatted evidence text</p> Source code in <code>app/tools/evidence.py</code> <pre><code>def retrieve_and_build_evidence(\n    tools: list,\n    query: str,\n    limit: int = 15\n) -&gt; str:\n    \"\"\"\n    Retrieve documents using selected tools and build formatted evidence.\n\n    Args:\n        tools (list): List of tool names selected by the planner\n        query (str): User question\n        limit (int): Maximum number of evidence entries\n\n    Returns:\n        str: Formatted evidence text\n    \"\"\"\n    all_docs = []\n\n    for tool_name in tools:\n        tool = TOOL_REGISTRY.get(tool_name)\n        if not tool:\n            continue\n\n        docs = tool[\"func\"](query)\n        all_docs.extend(docs)\n\n    return build_evidence(all_docs, limit=limit)\n</code></pre>"},{"location":"api/gradio_app/","title":"Gradio App","text":""},{"location":"api/gradio_app/#module-overview","title":"Module Overview","text":"<p>Gradio-based user interface for the Agentic RAG system.</p> <p>Responsibilities: - Provide a simple interactive UI for testing the agent - Forward user questions to the agent execution loop - Display the final answer and agent trace for auditability - Contain NO business, planning, or retrieval logic</p>"},{"location":"api/gradio_app/#app.ui.gradio_app.ask","title":"ask","text":"<pre><code>ask(question: str)\n</code></pre> <p>Handle a user question submitted from the UI.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>Natural language question entered by the user</p> required <p>Returns:</p> Name Type Description <code>Tuple</code> <ul> <li>str: Final agent answer or clarification question</li> <li>Dict: Agent execution trace (plan, tools used)</li> </ul> Source code in <code>app/ui/gradio_app.py</code> <pre><code>def ask(question: str):\n    \"\"\"\n    Handle a user question submitted from the UI.\n\n    Args:\n        question (str): Natural language question entered by the user\n\n    Returns:\n        Tuple:\n            - str: Final agent answer or clarification question\n            - Dict: Agent execution trace (plan, tools used)\n    \"\"\"\n    answer, trace = run_agent(question)\n    return answer, trace\n</code></pre>"},{"location":"api/gradio_app/#app.ui.gradio_app.launch","title":"launch","text":"<pre><code>launch()\n</code></pre> <p>Launch the Gradio application.</p> <p>UI Components: - Textbox for user questions - Markdown panel for the agent answer - JSON panel for agent trace (planner output, tools used)</p> Source code in <code>app/ui/gradio_app.py</code> <pre><code>def launch():\n    \"\"\"\n    Launch the Gradio application.\n\n    UI Components:\n    - Textbox for user questions\n    - Markdown panel for the agent answer\n    - JSON panel for agent trace (planner output, tools used)\n    \"\"\"\n    with gr.Blocks() as demo:\n        gr.Markdown(\"# Agentic RAG \u2013 Enterprise Knowledge Analyst\")\n\n        question = gr.Textbox(\n            label=\"Question\",\n            placeholder=\"Ask about Kubernetes, incidents, compliance, or APIs...\"\n        )\n\n        askQns = gr.Button(\"Ask Agent\")\n\n        answer = gr.Markdown(label=\"Answer\")\n        trace = gr.JSON(label=\"Agent Trace\")\n\n        askQns.click(\n            ask,\n            inputs=question,\n            outputs=[answer, trace]\n        )\n\n    demo.launch()\n</code></pre>"},{"location":"api/judge/","title":"Judge","text":""},{"location":"api/judge/#module-overview","title":"Module Overview","text":"<p>LLM-as-Judge module.</p> <p>Evaluates the quality of the agent's final answer based on grounding, relevance, and citation quality.</p>"},{"location":"api/judge/#app.agent.judge.judge_answer","title":"judge_answer","text":"<pre><code>judge_answer(question: str, answer: str, evidence: str) -&gt; dict\n</code></pre> <p>Evaluate the agent's answer using an LLM judge.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>Original user question</p> required <code>answer</code> <code>str</code> <p>Agent-generated answer</p> required <code>evidence</code> <code>str</code> <p>Evidence used for reasoning</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Structured evaluation verdict</p> Source code in <code>app/agent/judge.py</code> <pre><code>def judge_answer(question: str, answer: str, evidence: str) -&gt; dict:\n    \"\"\"\n    Evaluate the agent's answer using an LLM judge.\n\n    Args:\n        question (str): Original user question\n        answer (str): Agent-generated answer\n        evidence (str): Evidence used for reasoning\n\n    Returns:\n        dict: Structured evaluation verdict\n    \"\"\"\n    prompt = load_prompt(\"judge.txt\").format(\n        question=question,\n        answer=answer,\n        evidence=evidence\n    )\n\n    response = llm_fast.invoke(prompt).content.strip()\n    return json.loads(response)\n</code></pre>"},{"location":"api/planner/","title":"Planner","text":""},{"location":"api/planner/#module-overview","title":"Module Overview","text":"<p>Planner agent.</p> <p>Responsibilities: - Interpret user intent - Select which tools to invoke - Decide whether clarification is required</p>"},{"location":"api/planner/#app.agent.planner.create_plan","title":"create_plan","text":"<pre><code>create_plan(question: str) -&gt; Plan\n</code></pre> <p>Generate a structured execution plan from the user question.</p> Source code in <code>app/agent/planner.py</code> <pre><code>def create_plan(question: str) -&gt; Plan:\n    \"\"\"\n    Generate a structured execution plan from the user question.\n    \"\"\"\n\n    tools_desc = \"\\n\".join(\n        f\"- {name}: {meta['description']}\"\n        for name, meta in TOOL_REGISTRY.items()\n    )\n\n    prompt = load_prompt(\"planner.txt\").format(\n        question=question,\n        tools=tools_desc\n    )\n\n    response = llm_fast.invoke(prompt).content\n    return Plan(**json.loads(response))\n</code></pre>"},{"location":"api/reasoner/","title":"Reasoner","text":""},{"location":"api/reasoner/#module-overview","title":"Module Overview","text":"<p>Reasoning module for generating answers based on evidence.</p> <p>Responsibilities: - Formulate prompts combining questions and evidence - Invoke LLM for reasoning</p>"},{"location":"api/reasoner/#app.agent.reasoner.reason","title":"reason","text":"<pre><code>reason(question: str, evidence: str, critique: str | None = None) -&gt; str\n</code></pre> <p>Generate a reasoned answer based on the question and accumulated evidence.</p> Source code in <code>app/agent/reasoner.py</code> <pre><code>def reason(question: str, evidence: str, critique: str | None = None) -&gt; str:\n    \"\"\"\n    Generate a reasoned answer based on the question and accumulated evidence.\n    \"\"\"\n    prompt = load_prompt(\"reasoner.txt\").format(\n        question=question,\n        evidence=evidence,\n        critique=critique or \"None\"\n    )\n    return llm_reasoning.invoke(prompt).content\n</code></pre>"},{"location":"api/registry/","title":"Tool Registry","text":""},{"location":"api/registry/#module-overview","title":"Module Overview","text":"<p>Tool registry for agent tool discovery.</p> <p>Responsibilities: - Maintain a central registry of all tools - Store tool metadata (description, domains) - Enable planner-driven dynamic tool invocation</p>"},{"location":"api/registry/#app.tools.registry.register_tool","title":"register_tool","text":"<pre><code>register_tool(name: str, description: str, domains: List[str])\n</code></pre> <p>Decorator to register a function as an agent tool.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Tool name referenced by the planner</p> required <code>description</code> <code>str</code> <p>Natural language description of tool capability</p> required <code>domains</code> <code>List[str]</code> <p>Keywords describing tool domain knowledge</p> required Source code in <code>app/tools/registry.py</code> <pre><code>def register_tool(name: str, description: str, domains: List[str]):\n    \"\"\"\n    Decorator to register a function as an agent tool.\n\n    Args:\n        name: Tool name referenced by the planner\n        description: Natural language description of tool capability\n        domains: Keywords describing tool domain knowledge\n    \"\"\"\n    def decorator(func: Callable):\n        TOOL_REGISTRY[name] = {\n            \"func\": func,\n            \"description\": description.strip(),\n            \"domains\": domains,\n        }\n        return func\n    return decorator\n</code></pre>"},{"location":"api/retrieval_tools/","title":"Retrieval Tools","text":""},{"location":"api/retrieval_tools/#module-overview","title":"Module Overview","text":"<p>Vector-based retrieval tools.</p> <p>Responsibilities: - Wrap each vector store as a self-describing tool - Expose retrieval capability without routing logic</p>"},{"location":"api/retrieval_tools/#app.tools.retrieval_tools.search_incident_reports","title":"search_incident_reports","text":"<pre><code>search_incident_reports(query: str)\n</code></pre> <p>Search incident reports.</p> Source code in <code>app/tools/retrieval_tools.py</code> <pre><code>@register_tool(\n    name=\"search_incident_reports\",\n    description=\"Outages, postmortems, reliability incidents, root cause analysis.\",\n    domains=[\"incident\", \"outage\", \"postmortem\"]\n)\ndef search_incident_reports(query: str):\n    \"\"\"Search incident reports.\"\"\"\n    return vs_incidents.similarity_search(query, k=6)\n</code></pre>"},{"location":"api/retrieval_tools/#app.tools.retrieval_tools.search_kubernetes_docs","title":"search_kubernetes_docs","text":"<pre><code>search_kubernetes_docs(query: str)\n</code></pre> <p>Search Kubernetes documentation.</p> Source code in <code>app/tools/retrieval_tools.py</code> <pre><code>@register_tool(\n    name=\"search_kubernetes_docs\",\n    description=\"Kubernetes concepts, RBAC, workloads, networking, cluster operations.\",\n    domains=[\"kubernetes\", \"rbac\", \"k8s\"]\n)\ndef search_kubernetes_docs(query: str):\n    \"\"\"Search Kubernetes documentation.\"\"\"\n    return vs_k8s.similarity_search(query, k=6)\n</code></pre>"},{"location":"api/retrieval_tools/#app.tools.retrieval_tools.search_policy_docs","title":"search_policy_docs","text":"<pre><code>search_policy_docs(query: str)\n</code></pre> <p>Search policy documents.</p> Source code in <code>app/tools/retrieval_tools.py</code> <pre><code>@register_tool(\n    name=\"search_policy_docs\",\n    description=\"GDPR, privacy, compliance, regulatory requirements.\",\n    domains=[\"gdpr\", \"compliance\", \"policy\"]\n)\ndef search_policy_docs(query: str):\n    \"\"\"Search policy documents.\"\"\"\n    return vs_policy.similarity_search(query, k=6)\n</code></pre>"},{"location":"api/retrieval_tools/#app.tools.retrieval_tools.search_stackoverflow","title":"search_stackoverflow","text":"<pre><code>search_stackoverflow(query: str)\n</code></pre> <p>Search StackOverflow posts.</p> Source code in <code>app/tools/retrieval_tools.py</code> <pre><code>@register_tool(\n    name=\"search_stackoverflow\",\n    description=\"Community Q&amp;A for debugging, errors, and practical solutions.\",\n    domains=[\"stackoverflow\", \"error\", \"debugging\"]\n)\ndef search_stackoverflow(query: str):\n    \"\"\"Search StackOverflow posts.\"\"\"\n    return vs_stackoverflow.similarity_search(query, k=6)\n</code></pre>"}]}